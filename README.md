# SETC (A Standard Evaluation Tool for Chatbots)
Chatbot evaluation is really hard. There is no standard, and this is our attempt to at least address small parts of this issue.

Right now we using [ParlAi](http://parl.ai/) as our framework for data as well as experiments. We use [OpenMNT-py](https://github.com/OpenNMT/OpenNMT-py) for our experiments. All of our checkpoints will be made publicly available including all configurations. See this [link](http://chatbot-eval-data.s3-accelerate.amazonaws.com/results/available_checkpoints.txt) for checkpoints from the paper. 

Submit your model! Please take a look https://goo.gl/forms/26Wu13jYBpxWoAgx1

Amazon Mechanical Turk is not free... we are actively looking for funding.

Please find our paper [here](Chatbot_Evaluation_2018_COLING.pdf).

**WARNING: This is extremely alpha code!!!**


